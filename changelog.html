<!-- SPDX-License-Identifier: MIT -->
<!-- Copyright (C) 2022 Xilinx, Inc. -->
<!-- Copyright (C) 2022-2024 Advanced Micro Devices, Inc. -->
<!-- HTML header for doxygen 1.9.0-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AI Engine API User Guide: Changelog</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="tables.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow" style="height: 60px">
  <td id="projectlogo" style="vertical-align: middle; padding-left: 15px; padding-right: 30px"><img height="32" alt="Logo" src="amd-logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">AI Engine API User Guide<span id="projectnumber">&#160;(AIE-API)           2025.1</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('changelog.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Changelog</div></div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#jan_2025">January 2025</a></li>
<li class="level1"><a href="#vitis_2024_2">Vitis 2024.2</a></li>
<li class="level1"><a href="#vitis_2024_1">Vitis 2024.1</a></li>
<li class="level1"><a href="#vitis_2023_2">Vitis 2023.2</a></li>
<li class="level1"><a href="#vitis_2023_1">Vitis 2023.1</a></li>
<li class="level1"><a href="#vitis_2022_2">Vitis 2022.2</a></li>
<li class="level1"><a href="#vitis_2022_1">Vitis 2022.1</a></li>
<li class="level1"><a href="#vitis_2021_2">Vitis 2021.2</a></li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="jan_2025"></a>
January 2025</h1>
<h3>Global AIE API changes</h3>
<ul>
<li>
Added XDNA2 support </li>
</ul>
<h1><a class="anchor" id="vitis_2024_2"></a>
Vitis 2024.2</h1>
<h3>Documentation changes</h3>
<ul>
<li>
</li>
</ul>
<h3>Global AIE API changes</h3>
<ul>
<li>
Implement arbitrary vector and accum size support </li>
<li>
Add <a class="el" href="types_8hpp.html#structcbfloat16">cbfloat16</a> support on AIE-ML </li>
</ul>
<h3>Changes to data types</h3>
<ul>
<li>
accum: Implement construction from block_vector </li>
<li>
accum: Implement grow_replicate </li>
<li>
mask: Enable get_submask to work with ElemsOut less than word size </li>
<li>
mask: Implement insert and extract </li>
</ul>
<h3>Changes to operations</h3>
<ul>
<li>
fft: Implement dynamic vectorization support for AIE </li>
<li>
fft: Implement radix 2 and radix 4 <a class="el" href="types_8hpp.html#structcbfloat16">cbfloat16</a> support on AIE-ML </li>
<li>
mmul: Implement 8x8x8 <a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a> mmul mode on AIE-ML </li>
<li>
shuffle: Fix optimized code paths for when the shuffle mode is known at compile time </li>
</ul>
<h3>ADF integration</h3>
<ul>
<li>
Enable <a class="el" href="types_8hpp.html#structcbfloat16">cbfloat16</a> streams for AIE-ML </li>
<li>
Implement vector reads and writes on cascades </li>
</ul>
<h1><a class="anchor" id="vitis_2024_1"></a>
Vitis 2024.1</h1>
<h3>Documentation changes</h3>
<ul>
<li>
Further refactoring to remove detail namespace from documentation </li>
<li>
Document default accumulator type for given mul inputs </li>
<li>
Document float conversion implementations and behaviour </li>
</ul>
<h3>Global AIE API changes</h3>
<ul>
<li>
Add vector and accum template deduction guides </li>
<li>
Leverage <a class="el" href="group__group__init.html#gacb979d2a6a761089ac4a479b6cabbb5e" title="Returns a vector whose elements are initialized to zero.">aie::zeros</a> in place of aie:broadcast(0) internally to prevent non-trivial conversions </li>
<li>
Several refactors to isolate external interfaces from detail namespace </li>
<li>
Add clamp function </li>
<li>
Add <a class="el" href="group__group__arithmetic.html#gabad8a8fbfba2b1d3838eddc55584dce7" title="Returns a vector with the element-wise addition of the two input vectors.">aie::saturating_add</a> <a class="el" href="group__group__arithmetic.html#ga7cbff5c7c9e805d504613fa9ee04efe5" title="Returns a vector with the element-wise subtraction of the two input vectors.">aie::saturating_sub</a> functions </li>
<li>
Add <a class="el" href="group__group__reshape.html#ga5d8153ea6de2d58816ddd0275497f9b6" title="Return the real component of a complex value.">aie::real</a> and <a class="el" href="group__group__reshape.html#ga61bca811fa4b427c9a8e490763e9d334" title="Return the imaginary component of a complex value.">aie::imag</a> helpers to get real and imaginary parts of vectors </li>
</ul>
<h3>Changes to data types</h3>
<ul>
<li>
accum: Fix sub-accum insertion </li>
<li>
vector: Optimize vector::get for 1K vectors </li>
<li>
vector: Extend pack/unpack to work for arbitrary conversions </li>
<li>
tensor_buffer_stream: Fix native implementations for non-native vector sizes </li>
</ul>
<h3>Changes to operations</h3>
<ul>
<li>
accumulate: Add array-based interface as alternative to variadic interface </li>
<li>
compare: Add workaround for IEEE incompliance to equality comparisons for <a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a> on AIE-ML </li>
<li>
compare: Optimize comparisons with zero </li>
<li>
compare: Fix scalar/vector comparisons on AIE </li>
<li>
concat: Add support for concatenating tuples of vectors/accumulators </li>
<li>
elementary: Optimize vector unrolling for scalar functions </li>
<li>
fft: Fix vectorization limits for odd-radix implementations </li>
<li>
fft: Add radix2 combiner for cint16 input/output with cint32 twiddles </li>
<li>
fft: Add radix3 and radix5 stage0 implementations on AIE-ML </li>
<li>
fft: Add cfloat radix3 and radix5 stage0 implementations on AIE </li>
<li>
fft: Add 32b twiddle up/down dit FFTs </li>
<li>
mmul: Add dynamic sign support for sparse_vector </li>
<li>
mmul: Implemented additional modes <ul>
<li>
AIE-ML: 16b x 8b - 8x4x8 , 32b x 16b - 4x4x8, bf16 x bf16 - 4x8x8 </li>
</ul>
</li>
<li>
mmul: Add some outer product modes as <a class="el" href="namespaceaie.html#a43a139787b463ec1b70e6d1e25621808">aie::mmul&lt;M,1,N&gt;</a> </li>
<li>
mmul: Enable zeroization for fp32 mmuls </li>
<li>
mul: Implement cint32 * int16 and int16 * cint32 muls </li>
<li>
neg: Add <a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a> support for AIE-ML </li>
<li>
sliding_mul: Optimize complex x real implementations </li>
<li>
sliding_mul: Add <a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a> support on AIE-ML </li>
<li>
to_fixed/to_float: Add support for unsigned types on AIE-ML </li>
</ul>
<h3>ADF integration</h3>
<ul>
<li>
Fix cfloat stream reads </li>
</ul>
<h1><a class="anchor" id="vitis_2023_2"></a>
Vitis 2023.2</h1>
<h3>Documentation changes</h3>
<ul>
<li>
Integrate AIE-ML documentation </li>
<li>
Document rounding modes </li>
<li>
Expand accumulate documentation </li>
<li>
Clarify limitations on 8b parallel lookup </li>
<li>
Fix mmul member documentation </li>
<li>
Clarify requirement for linear_approx step bits </li>
<li>
Improve documentation of vector, accum, and mask </li>
<li>
Highlight architecture requirements of functions using C++ requires clauses </li>
<li>
Document FFT twiddle factor generation </li>
<li>
Clarify internal rounding mode for <a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a> to integer conversion </li>
<li>
Clarify native and emulated modes for mmul </li>
<li>
Clarify native and emulated modes for sliding_mul </li>
<li>
Document sparse_vector_input_buffer_stream with memory layout and GEMM example </li>
<li>
Document tensor_buffer_stream with a GEMM example </li>
</ul>
<h3>Global AIE API changes</h3>
<ul>
<li>
Add cfloat support for AIE-ML </li>
</ul>
<h3>Changes to data types</h3>
<ul>
<li>
vector: Optimize grow_replicate on AIE-ML </li>
<li>
mmul: Support reinitialization from an accum </li>
<li>
DM resources: Add compound aie_dm_resource variants </li>
<li>
streams: Add sparse_vector_input_buffer_stream for loading sparse data on AIE-ML </li>
<li>
streams: Add tensor_buffer_stream to handle multi-dimensional addressing for AIE-ML </li>
<li>
<a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a>: Add specialization for std::numeric_limits on AIE-ML </li>
</ul>
<h3>Changes to operations</h3>
<ul>
<li>
abs: Fix for float input </li>
<li>
add_reduce: Optimize for 8b and 16b types on AIE-ML </li>
<li>
div: Implement vector-vector and vector-scalar division </li>
<li>
downshift: Implement logical_downshift for AIE </li>
<li>
fft: Add support for 32 bit twiddles on AIE </li>
<li>
fft: Fix for radix-3 and radix-5 FFTs on AIE </li>
<li>
fft: Fix radix-5 performance for low vectorizations on AIE </li>
<li>
fft: Add stage-based FFT functions and deprecate iterator interface </li>
<li>
mul: Fix for vector * vector_elem_ref on AIE </li>
<li>
print_fixed: Support printing Q format data </li>
<li>
print_matrix: Added accumulator support </li>
<li>
sliding_mul: Add support float </li>
<li>
sliding_mul: Add support for remaining 32b modes for AIE-ML </li>
<li>
sliding_mul: Add support for Points &lt; Native Points </li>
<li>
sliding_mul_ch: Fix DataStepX == DataStepY requirement </li>
<li>
sincos: Optimize AIE implementation </li>
<li>
to_fixed: Fix for AIE-ML </li>
<li>
to_fixed/to_float: Add vectorized float conversions for AIE </li>
<li>
to_fixed/to_float: Add generic conversions ((int8, int16, int32) &lt;-&gt; (<a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a>, float)) for AIE-ML </li>
</ul>
<h3>ADF integration</h3>
<ul>
<li>
Add TLAST support for stream reads on AIE-ML </li>
<li>
Add support for input_cascade and output_cascade types </li>
<li>
Deprecate accum reads from input_stream and output_stream </li>
</ul>
<h1><a class="anchor" id="vitis_2023_1"></a>
Vitis 2023.1</h1>
<h3>Documentation changes</h3>
<ul>
<li>
Add explanation of FFT inputs </li>
<li>
Use block_size in FFT docs </li>
<li>
Clarify matrix data layout expectations </li>
<li>
Clarify downshift being arithmetic </li>
<li>
Correct description of <a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a> linear_approx lookup table </li>
</ul>
<h3>Global AIE API changes</h3>
<ul>
<li>
Do not explicitly initialize inferred template arguments </li>
<li>
More aggressive inlining of internal functions </li>
<li>
Avoid using 128b vectors in stream helper functions for AIE-ML </li>
</ul>
<h3>Changes to data types</h3>
<ul>
<li>
iterator: Do not declare iterator data members as const </li>
<li>
mask: Optimized implementation for 64b masks on AIE-ML </li>
<li>
mask: New constructors added to initialize the mask from uint32 or uint64 values </li>
<li>
vector: Fix 1024b inserts </li>
<li>
vector: Use 128b concats in upd_all </li>
<li>
vector: Fix 8b unsigned to_vector for AIE-ML </li>
</ul>
<h3>Changes to operations</h3>
<ul>
<li>
add/sub: Support for dynamic accumulator zeroization </li>
<li>
begin_restrict_vector: Add implementation for io_buffer </li>
<li>
eq: Add support for complex numbers </li>
<li>
fft: Correctly set radix configuration in fft::begin_stage calls </li>
<li>
inv/invsqrt: Add implementation for AIE-ML </li>
<li>
linear_approx: Performance optimization for AIE-ML </li>
<li>
logical_downshift: New function that implements a logical downshift (as opposed to <a class="el" href="group__group__bit.html#gae3dec518599b518dcdec044d4c645c6d" title="Returns a vector with all values arithmetically downshifted by specified number of bits.">aie::downshift</a>, which is arithmetic) </li>
<li>
max/min/maxdiff: Add support for dynamic sign </li>
<li>
mmul: Implement 16b 8x2x8 mode for AIE-ML </li>
<li>
mmul: Implement 8b 8x8x8 mode for AIE-ML </li>
<li>
mmul: Implemet missing 16b x 8b and 8b x 4b sparse multiplication modes for AIE-ML </li>
<li>
neq: Add support for complex numbers </li>
<li>
parallel_lookup: Optimize implementation for signed truncation </li>
<li>
print_matrix: New function that prints vectors with the specified matrix shape </li>
<li>
shuffle_up/down: Minor optimization for 16b </li>
<li>
shuffle_up/down: Optimized implementation for AIE-ML </li>
<li>
sliding_mul: Support data_start/coeff_start values larger than vector size </li>
<li>
sliding_mul: Add support for 32b modes for AIE-ML </li>
<li>
sliding_mul: Add 2 point 16b 16 channel for AIE-ML </li>
<li>
sliding_mul_ch: New function for multi-channel multiplication modes for AIE-ML </li>
<li>
sliding_mul_sym_uct: Fix for 16b two-buffer implementation </li>
<li>
store_unaligned_v: Optimized implementation for AIE-ML </li>
<li>
transpose: Add support for 64b and 32b types </li>
<li>
transpose: Enable transposition of 256 element 4b vectors (scalar implementation for now) </li>
<li>
to_fixed: Add <a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a> to int32 conversion on AIE-ML </li>
</ul>
<h1><a class="anchor" id="vitis_2022_2"></a>
Vitis 2022.2</h1>
<h3>Documentation changes</h3>
<ul>
<li>
Add code samples for load_v/store_v and load_unaligned_v/store_unaligned_v </li>
<li>
Enhanced documentation for parallel_lookup and linear_approx </li>
<li>
Clarify coeff vector size limit on AIE-ML </li>
</ul>
<h3>Global AIE API changes</h3>
<ul>
<li>
Remove usage of srs in compare functions, to avoid compilation warnings as it is deprecated </li>
<li>
Add support for stream ADF vector types on AIE-ML </li>
</ul>
<h3>Changes to data types</h3>
<ul>
<li>
mask: add shift operators </li>
<li>
saturation_mode: add saturate value. It was previously named truncate, which is not correct. The old name is also kept until it is deprecated </li>
</ul>
<h3>Changes to operations</h3>
<ul>
<li>
add: support accumulator addition on AIE-ML </li>
<li>
add_reduce: add optimized implementation for cfloat on AIE </li>
<li>
add_reduce: add optimized implementation for <a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a> on AIE-ML </li>
<li>
eq/neq: enhanced implementation on AIE-ML </li>
<li>
le: enhanced implementation on AIE-ML </li>
<li>
load_unaligned_v: leverage pointer truncation to 128b done by HW on AIE </li>
<li>
fft: add support for radix 3/5 on AIE </li>
<li>
mmul: add matrix x vector multiplicatio modes on AIE </li>
<li>
mmul: add support for dynamic accumulator zeroization </li>
<li>
to_fixed: added implementation for AIE-ML </li>
<li>
to_fixed: provide a default return type </li>
<li>
to_float: added implementation for AIE-ML </li>
<li>
reverse: optimized implementation for 32b and 64b on AIE-ML </li>
<li>
zeros: include fixes on AIE </li>
</ul>
<h1><a class="anchor" id="vitis_2022_1"></a>
Vitis 2022.1</h1>
<h3>Documentation changes</h3>
<ul>
<li>
Small documentation fixes for operators </li>
<li>
Issues of documentation on msc_square and mmul </li>
<li>
Enhance documentation for sliding_mul operations </li>
<li>
Change logo in documentation </li>
<li>
Add documentation for ADF stream operators </li>
</ul>
<h3>Global AIE API changes</h3>
<ul>
<li>
Add support for emulated FP32 data types and operations on AIE-ML </li>
</ul>
<h3>Changes to data types</h3>
<ul>
<li>
unaligned_vector_iterator: add new type and helper functions </li>
<li>
random_circular_vector_iterator: add new type and helper functions </li>
<li>
iterator: add linear iterator type and helper functions for scalar values </li>
<li>
accum: add support for dynamic sign in to/from_vector on AIE-ML </li>
<li>
accum: add implicit conversion to float on AIE-ML </li>
<li>
vector: add support for dynamic sign in pack/unpack </li>
<li>
vector: optimization of initialization by value on AIE-ML </li>
<li>
vector: add constructor from 1024b native types on AIE-ML </li>
<li>
vector: fixes and optimizations for unaligned_load/store </li>
</ul>
<h3>Changes to operations</h3>
<ul>
<li>
adf::buffer_port: add many wrapper iterators </li>
<li>
adf::stream: annotate read/write functions with stream resource so they can be scheduled in parallel </li>
<li>
adf::stream: add stream operator overloading </li>
<li>
fft: performance fixes on AIE-ML </li>
<li>
max/min/maxdiff: add support for <a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a> and float on AIE-ML </li>
<li>
mul/mmul: add support for <a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a> and float on AIE-ML </li>
<li>
mul/mmul: add support for dynamic sign AIE-ML </li>
<li>
parallel_lookup: expanded to int16-&gt;bfloat, performance optimisations, and softmax kernel </li>
<li>
print: add support to print accumulators </li>
<li>
add/max/min_reduce: add support for float on AIE-ML </li>
<li>
reverse: add optimized implementation on AIE-ML using matrix multiplications </li>
<li>
shuffle_down_replicate: add new function </li>
<li>
sliding_mul: add 32b for 8b * 8b and 16b * 16b on AIE-ML </li>
<li>
transpose: add new function and implementation for AIE-ML </li>
<li>
upshift/downshift: add implementation for AIE-ML </li>
</ul>
<h1><a class="anchor" id="vitis_2021_2"></a>
Vitis 2021.2</h1>
<h3>Documentation changes</h3>
<ul>
<li>
Fix description of sliding_mul_sym_uct </li>
<li>
Make return types explicit for better documentation </li>
<li>
Fix documentation for sin/cos so that it says that the input must be in radians </li>
<li>
Add support for concepts </li>
<li>
Add documenttion for missing arguments and fix wrong argument names </li>
<li>
Fixes in documentation for int4/uint4 AIE-ML types </li>
<li>
Add documentation for the mmul class </li>
<li>
Update documentation about supported accumulator sizes </li>
<li>
Update the matrix multiplication example to use the new MxKxN scheme and size_A/size_B/size_C </li>
</ul>
<h3>Global AIE API changes</h3>
<ul>
<li>
Make all entry points always_inline </li>
<li>
Add declaration macros to aie_declaration.hpp so that they can be used in headers parsed by aiecompiler </li>
</ul>
<h3>Changes to data types</h3>
<ul>
<li>
Add support for <a class="el" href="types_8hpp.html#structbfloat16">bfloat16</a> data type on AIE-ML </li>
<li>
Add support for cint16/cint32 data types on AIE-ML </li>
<li>
Add an argument to vector::grow, to specify where the input vector will be located in the output vector </li>
<li>
Remove copy constructor so that the vector type becomes trivial </li>
<li>
Remove copy constructor so that the mask type becomes trivial </li>
<li>
Make all member functions in circular_index constexpr </li>
<li>
Add tiled_mdspan::begin_vector_dim functions that return vector iterators </li>
<li>
Initial support for sparse vectors on AIE-ML, including iterators to read from memory </li>
<li>
Make vector methods always_inline </li>
<li>
Make vector::push be applied to the object it is called on and return a reference </li>
</ul>
<h3>Changes to operations</h3>
<ul>
<li>
<p class="startli">add: Implementation optimization on AIE-ML</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">add_reduce: Implement on AIE-ML</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">bit/or/xor: Implement scalar x vector variants of bit operations</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">equal/not_equal: Add fix in which not all lanes were being compared for certain vector sizes.</p>
<p class="endli"></p>
</li>
<li>
fft: Interface change to enhance portability across AIE/AIE-ML </li>
<li>
fft: Add initial support on AIE-ML </li>
<li>
fft: Add alignment checks for x86sim in FFT iterators </li>
<li>
<p class="startli">fft: Make FFT output interface uniform for radix 2 cint16 upscale version on AIE</p>
<p class="endli"></p>
</li>
<li>
filter_even/filter_odd: Functional fixes </li>
<li>
filter_even/filter_odd: Performance improvement for 4b/8b/16b implementations </li>
<li>
filter_even/filter_odd: Performance optimization on AIE-ML </li>
<li>
<p class="startli">filter_even/filter_odd: Do not require step argument to be a compile-time constant</p>
<p class="endli"></p>
</li>
<li>
interleave_zip/interleave_unzip: Improve performance when configuration is a run-time value </li>
<li>
<p class="startli">interleave_*: Do not require step argument to be a compile-time constant</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">load_floor_v/load_floor_bytes_v: New functions that floor the pointer to a requested boundary before performing the load.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">load_unaligned_v/store_unaligned_v: Performance optimization on AIE-ML</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">lut/parallel_lookup/linear_approx: First implementation of look-up based linear functions on AIE-ML.</p>
<p class="endli"></p>
</li>
<li>
max_reduce/min_reduce: Add 8b implementation </li>
<li>
<p class="startli">max_reduce/min_reduce: Implement on AIE-ML</p>
<p class="endli"></p>
</li>
<li>
mmul: Implement new shapes for AIE-ML </li>
<li>
mmul: Initial support for 4b multiplication </li>
<li>
mmul: Add support for 80b accumulation for 16b x 32b / 32b x 16b cases </li>
<li>
mmul: Change dimension names from MxNxK to MxKxN </li>
<li>
<p class="startli">mmul: Add size_A/size_B/size_C data members</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">mul: Optimized mul+conj operations to merged into a single intrinsic call on AIE-ML</p>
<p class="endli"></p>
</li>
<li>
sin/cos/sincos: Fix to avoid int -&gt; unsigned conversions that reduce the range </li>
<li>
sin/cos/sincos: Use a compile-time division to compute 1/PI </li>
<li>
sin/cos/sincos: Fix floating-point range </li>
<li>
<p class="startli">sin/cos/sincos: Optimized implementation for float vector</p>
<p class="endli"></p>
</li>
<li>
shuffle_up/shuffle_down: Elements don't wrap around anymore. Instead, new elements are undefined. </li>
<li>
shuffle_up_rotate/shuffle_down_rotate: New variants added for the cases in which elements need to wrap-around </li>
<li>
shuffle_up_replicate: Variant added which replicates the first element. </li>
<li>
shuffle_up_fill: Variant added which fills new elements with elements from another vector. </li>
<li>
<p class="startli">shuffle_*: Optimization in shuffle primitives on AIE, especially for 8b/16b cases</p>
<p class="endli"></p>
</li>
<li>
sliding_mul: Fixes to handle larger Step values for cfloat variants </li>
<li>
sliding_mul: Initial implementation for 16b x 16b and cint16b x cint16b on AIE-ML </li>
<li>
<p class="startli">sliding_mul: Optimized mul+conj operations to merged into a single intrinsic call on AIE-ML</p>
<p class="endli"></p>
</li>
<li>
sliding_mul_sym: Fixes in start computation for filters with DataStepX &gt; 1 </li>
<li>
sliding_mul_sym: Add missing int32 x int16 / int16 x int32 type combinations </li>
<li>
sliding_mul_sym: Fix two-buffer sliding_mul_sym <a class="el" href="group__group__basic__types__accum.html#structacc80" title="Tag used to request an accumulator with at least 80 bit per element.">acc80</a> </li>
<li>
<p class="startli">sliding_mul_sym: Add support for separate left/right start arguments</p>
<p class="endli"></p>
</li>
<li>
store_v: Support pointers annotated with storage attributes </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- SPDX-License-Identifier: MIT -->
<!-- Copyright (C) 2022 Xilinx, Inc. -->
<!-- Copyright (C) 2022-2024 Advanced Micro Devices, Inc. -->
<!-- HTML footer for doxygen 1.9.0-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">UG1529 &copy; 2024 Advanced Micro Devices, Inc. All rights reserved.</li>
  </ul>
</div>
</body>
</html>
